{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS to Run Code\n",
    "\n",
    "If your local machine has limited computing resources, you can use cloud computing services to obtain more powerful computing resources and use them to run the deep learning code in this document. In this section, we will show you how to apply for instances and use Jupyter Notebook to run code on AWS (Amazon's cloud computing service). The example here includes two steps:\n",
    "\n",
    "1. Apply for a K80 GPU \"p2.xlarge\" instance.\n",
    "2. Install CUDA and the corresponding MXNet GPU version.\n",
    "\n",
    "The process to apply for other instance types and install other MXNet versions is basically the same as that described here.\n",
    "\n",
    "\n",
    "## Apply for an Account and Log In\n",
    "\n",
    "First, we need to register an account at https://aws.amazon.com/. It usually requires a credit card.\n",
    "\n",
    "After logging into your AWS account, click \"EC2\" (marked by the red box in Figure 11.8) to go to the EC2 panel.\n",
    "\n",
    "![ Log into your AWS account. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/aws.png)\n",
    "\n",
    "\n",
    "## Create and Run an EC2 Instance\n",
    "\n",
    "Figure 11.9 shows the EC2 panel. In the area marked by the red box in Figure 11.9, select a nearby data center to reduce latency. If you are located in China you can select a nearby Asia Pacific region, such as Asia Pacific (Seoul). Please note that some data centers may not have GPU instances. Click the \"Launch Instance\" button marked by the red box in Figure 11.8 to launch your instance.\n",
    "\n",
    "![ EC2 panel. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/ec2.png)\n",
    "\n",
    "\n",
    "The row at the top of Figure 11.10 shows the seven steps in the instance configuration process. In the first step \"1. Choose AMI\", choose Ubuntu 16.04 for the operating system.\n",
    "\n",
    "![ Choose an operating system. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/os.png)\n",
    "\n",
    "EC2 provides many different instance configurations to choose from. As shown in Figure 11.11, In \"Step 2: Choose an Instance Type”，choose a \"p2.xlarge\" instance with K80 GPU. We can also choose instances with multiple GPUs such as \"p2.16xlarge\". If you want to compare machine configurations and fees of different instances, you may refer to https://www.ec2instances.info/.\n",
    "\n",
    "![ Choose an instance. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/p2x.png)\n",
    "\n",
    "Before choosing an instance, we suggest you check if there are quantity restrictions by clicking the \"Limits\" label in the bar on the, as left shown in Figure 11.9. As shown in Figure 11.12, this account can only open one \"p2.xlarge\" instance per region. If you need to open more instances, click on the \"Request limit increase\" link to apply for a higher instance quota. Generally, it takes one business day to process an application.\n",
    "\n",
    "![ Instance quantity restrictions. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/limits.png)\n",
    "\n",
    "In this example, we keep the default configurations for the steps \"3. Configure Instance\", \"5. Add Tags\", and \"6. Configure Security Group\". Tap on \"4. Add Storage\" and increase the default hard disk size to 40 GB. Note that you will need about 4 GB to install CUDA.\n",
    "\n",
    "![ Modify instance hard disk size. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/disk.png)\n",
    "\n",
    "\n",
    "Finally, go to \"7. Review\" and click \"Launch\" to launch the configured instance. The system will now prompt you to select the key pair used to access the instance. If you do not have a key pair, select \"Create a new key pair\" in the first drop-down menu in Figure 11.14 to generate a key pair. Subsequently, you can select \"Choose an existing key pair\" for this menu and then select the previously generated key pair. Click \"Launch Instances\" to launch the created instance.\n",
    "\n",
    "![ Select a key pair. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/keypair.png)\n",
    "\n",
    "Click the instance ID shown in Figure 11.15 to view the status of this instance.\n",
    "\n",
    "![C lick the instance ID. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/launching.png)\n",
    "\n",
    "As shown in Figure 11.16, after the instance state turns green, right-click the instance and select \"Connect\" to view the instance access method. For example, enter the following in the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ssh -i \"/path/to/key.pem\" ubuntu@ec2-xx-xxx-xxx-xxx.y.compute.amazonaws.com\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"/path/to/key.pem\" is the path of the locally-stored key used to access the instance. When the command line prompts \"Are you sure you want to continue connecting (yes/no)\", enter \"yes\" and press Enter to log into the instance.\n",
    "\n",
    "![ View instance access and startup method. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/connect.png)\n",
    "\n",
    "\n",
    "## Install CUDA\n",
    "\n",
    "If you log into a GPU instance, you need to download and install CUDA. First, update and install the package needed for compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sudo apt-get update && sudo apt-get install -y build-essential git libgfortran3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA releases a major version of CUDA every year. Here we download the latest CUDA 9.0 when the book is written. Visit the official website of NVIDIA (https://developer.nvidia.com/cuda-90-download-archive) to obtain the download link of CUDA 9.0, as shown in Figure 11.17.\n",
    "\n",
    "![Find the CUDA 9.0 download address. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/cuda.png)\n",
    "\n",
    "\n",
    "After finding the download address, download and install CUDA 9.0. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# The download link and file name are subject to change, so always use those\n",
    "# from the NVIDIA website\n",
    "wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run\n",
    "sudo sh cuda_9.0.176_384.81_linux-run\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press \"Ctrl+C\" to jump out of the document and answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Do you accept the previously read EULA?\n",
    "accept/decline/quit: accept\n",
    "Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?\n",
    "(y)es/(n)o/(q)uit: y\n",
    "Do you want to install the OpenGL libraries?\n",
    "(y)es/(n)o/(q)uit [ default is yes ]: y\n",
    "Do you want to run nvidia-xconfig?\n",
    "This will ... vendors.\n",
    "(y)es/(n)o/(q)uit [ default is no ]: n\n",
    "Install the CUDA 9.0 Toolkit?\n",
    "(y)es/(n)o/(q)uit: y\n",
    "Enter Toolkit Location\n",
    " [ default is /usr/local/cuda-9.0 ]:\n",
    "Do you want to install a symbolic link at /usr/local/cuda?\n",
    "(y)es/(n)o/(q)uit: y\n",
    "Install the CUDA 9.0 Samples?\n",
    "(y)es/(n)o/(q)uit: n\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the program, run the following command to view the instance GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nvidia-smi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add CUDA to the library path to help other libraries find it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "echo \"export LD_LIBRARY_PATH=\\${LD_LIBRARY_PATH}:/usr/local/cuda-9.0/lib64\" >> ~/.bashrc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire the Code for this Book and Install MXNet GPU Version\n",
    "\n",
    "We have introduced the way to obtaining code of the book and setting up the running environment in Section [\"Getting started with Gluon\"](../chapter_prerequisite/install.md). First, install Miniconda of the Linux version (website: https://conda.io/miniconda.html), such as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# The download link and file name are subject to change, so always use those\n",
    "# from the Miniconda website\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "sudo sh Miniconda3-latest-Linux-x86_64.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Do you accept the license terms? [yes|no]\n",
    "[no] >>> yes\n",
    "Do you wish the installer to prepend the Miniconda3 install location\n",
    "to PATH in your /home/ubuntu/.bashrc ? [yes|no]\n",
    "[no] >>> yes\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installation, run `source ~/.bashrc` once to activate CUDA and Conda. Next, download the code for this book and install and activate the Conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mkdir d2l-en && cd d2l-en\n",
    "curl https://www.d2l.ai/d2l-en-1.0.zip -o d2l-en.zip\n",
    "unzip d2l-en.zip && rm d2l-en.zip\n",
    "conda env create -f environment.yml\n",
    "source activate gluon\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MXNet CPU version is installed in the environment by default. Now, you must replace it with the MXNet GPU version. As the CUDA version is 9.0, install `mxnet-cu90`. Generally speaking, if your CUDA version is x.y, the corresponding MXNET version is `mxnet-cuxy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip uninstall mxnet\n",
    "# X.Y.Z should be replaced with the version number depended on by the book\n",
    "pip install mxnet-cu90==X.Y.Z\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Jupyter Notebook\n",
    "\n",
    "Now, you can run Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "jupyter notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 11.18 shows the possible output after you run Jupyter Notebook. The last row is the URL for port 8888.\n",
    "\n",
    "![ Output after running Jupyter Notebook. The last row is the URL for port 8888. ](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/jupyter.png)\n",
    "\n",
    "Because the instance you created does not expose port 8888, you can launch SSH in the local command line and map the instance to the local port 8889."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# This command must be run in the local command line\n",
    "ssh -i \"/path/to/key.pem\" ubuntu@ec2-xx-xxx-xxx-xxx.y.compute.amazonaws.com -L 8889:localhost:8888\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, copy the URL shown in the last line of the Jupyter Notebook output in Figure 11.18 to your local browser and change 8888 to 8889. Press Enter to use Jupyter Notebook to run the instance code from your local browser.\n",
    "\n",
    "## Close Unused Instances\n",
    "\n",
    "As cloud services are billed by use duration, you will generally want to close instances you no longer use.\n",
    "\n",
    "If you plan on restarting the instance after a short time, right-click on the example shown in Figure 11.16 and select \"Instance State\" $\\rightarrow$ \"Stop\" to stop the instance. When you want to use it again, select \"Instance State\" $\\rightarrow$ \"Start\" to restart the instance. In this situation, the restarted instance will retain the information stored on its hard disk before it was stopped (for example, you do not have to reinstall CUDA and other runtime environments). However, stopped instances will still be billed a small amount for the hard disk space retained.\n",
    "\n",
    "If you do not plan to use the instance again for a long time, right-click on the example in Figure 11.16 and select \"Image\" $\\rightarrow$ \"Create\" to create an image of the instance. Then, select \"Instance State\" $\\rightarrow$ \"Terminate\" to terminate the instance (it will no longer be billed for hard disk space). The next time you want to use this instance, you can follow the steps for creating and running an EC2 instance described in this section to create an instance based on the saved image. The only difference is that, in \"1. Choose AMI\" shown in Figure 11.10, you must use the \"My AMIs\" option on the left to select your saved image. The created instance will retain the information stored on the image hard disk. For example, you will not have to reinstall CUDA and other runtime environments.\n",
    "\n",
    "## Summary\n",
    "\n",
    "* You can use cloud computing services to obtain more powerful computing resources and use them to run the deep learning code in this document.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "* The cloud offers convenience, but it does not come cheap. Research the prices of cloud services and find ways to reduce overhead.\n",
    "\n",
    "## Scan the QR Code to [Discuss](https://discuss.mxnet.io/t/2399)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/qr_aws.png\" alt=\"\" width=75 height=75/>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}